{"cells": [{"cell_type": "markdown", "id": "af9042e9-4e6a-44a8-a41d-ed472d238aca", "metadata": {}, "source": "### Objective:\n\n- Save and retrieve processed data efficiently inside Dataproc.\n- Serve data in a structured way for analysis.\n- Use Parquet, Hive, and CSV "}, {"cell_type": "code", "execution_count": 2, "id": "179f1f1f-7c41-4573-85a1-40a1a2566ad0", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 3, "id": "71e2f0df-285b-43dc-a0b2-973d931c421b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/09/20 15:45:23 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "spark = SparkSession.builder \\\n.appName('Olist Ecommerce Performance Optmization') \\\n.config('spark.executor.memory','6g') \\\n.config('spark.executor.cores','4') \\\n.config('spark.executor.instances','2') \\\n.config('spark.driver.memory','4g') \\\n.config('spark.driver.maxResultSize','2g') \\\n.config('spark.sql.shuffle.partitions','64') \\\n.config('spark.default.parallelism','64') \\\n.config('spark.sql.adaptive.enabled','true') \\\n.config('spark.sql.adaptive.coalescePartition.enabled','true') \\\n.config('spark.sql.autoBroadcastJoinThreshold',20*1024*1024) \\\n.config('spark.sql.files.maxPartitionBytes','64MB') \\\n.config('spark.sql.files.openCostInBytes','2MB') \\\n.config('spark.memory.fraction',0.8) \\\n.config('spark.memory.storageFraction',0.2) \\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 4, "id": "a2247381-6468-4971-ad98-d7ac14a59e21", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "full_orders_df = spark.read.parquet('/data/olist/processed/')"}, {"cell_type": "code", "execution_count": 5, "id": "55509ce5-321e-47d0-8509-8fa39e79a081", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- customer_id: string (nullable = true)\n |-- order_id: string (nullable = true)\n |-- seller_id: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- order_status: string (nullable = true)\n |-- order_purchase_timestamp: timestamp (nullable = true)\n |-- order_approved_at: timestamp (nullable = true)\n |-- order_delivered_carrier_date: timestamp (nullable = true)\n |-- order_delivered_customer_date: timestamp (nullable = true)\n |-- order_estimated_delivery_date: timestamp (nullable = true)\n |-- order_item_id: integer (nullable = true)\n |-- shipping_limit_date: timestamp (nullable = true)\n |-- price: double (nullable = true)\n |-- freight_value: double (nullable = true)\n |-- product_category_name: string (nullable = true)\n |-- product_name_lenght: integer (nullable = true)\n |-- product_description_lenght: integer (nullable = true)\n |-- product_photos_qty: integer (nullable = true)\n |-- product_weight_g: integer (nullable = true)\n |-- product_length_cm: integer (nullable = true)\n |-- product_height_cm: integer (nullable = true)\n |-- product_width_cm: integer (nullable = true)\n |-- seller_zip_code_prefix: integer (nullable = true)\n |-- seller_city: string (nullable = true)\n |-- seller_state: string (nullable = true)\n |-- customer_unique_id: string (nullable = true)\n |-- customer_zip_code_prefix: integer (nullable = true)\n |-- customer_city: string (nullable = true)\n |-- customer_state: string (nullable = true)\n |-- geolocation_zip_code_prefix: integer (nullable = true)\n |-- geolocation_lat: double (nullable = true)\n |-- geolocation_lng: double (nullable = true)\n |-- geolocation_city: string (nullable = true)\n |-- geolocation_state: string (nullable = true)\n |-- review_id: string (nullable = true)\n |-- review_score: string (nullable = true)\n |-- review_comment_title: string (nullable = true)\n |-- review_comment_message: string (nullable = true)\n |-- review_creation_date: string (nullable = true)\n |-- review_answer_timestamp: string (nullable = true)\n |-- payment_sequential: integer (nullable = true)\n |-- payment_type: string (nullable = true)\n |-- payment_installments: integer (nullable = true)\n |-- payment_value: double (nullable = true)\n |-- is_delivered: integer (nullable = true)\n |-- is_canceled: integer (nullable = true)\n |-- order_revenue: double (nullable = true)\n |-- customer_segment: string (nullable = true)\n |-- hour_of_day: integer (nullable = true)\n |-- order_day_type: string (nullable = true)\n\n"}], "source": "full_orders_df.printSchema()"}, {"cell_type": "code", "execution_count": 6, "id": "a2f779f0-cd80-4493-9eb6-13a9f9ced63d", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/09/20 15:45:30 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n                                                                                \r"}], "source": "# save as Parquet in hdfs\n\nfull_orders_df.write.mode('overwrite').parquet('/data/olist/proc')"}, {"cell_type": "code", "execution_count": null, "id": "dd303a62-3587-4a37-bfee-383559d260bd", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "cb048b72-b60a-4a2b-8a98-c81c1df68574", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 2:===================>                                       (1 + 2) / 3]\r"}], "source": "# Save is as a parquet in Google cloud storage\n\nfull_orders_df.write.mode('overwrite').parquet('gs://dataproc-staging-us-central1-870618479357-obiyadgs/temp_data')"}, {"cell_type": "code", "execution_count": null, "id": "d8116771-f5b2-421b-8442-7019f3bcaf99", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "99ae37b9-2b3d-4d52-83ec-2cd3f8db0f4a", "metadata": {"tags": []}, "outputs": [], "source": "full_orders_df.write.mode('overwrite').saveAsTable('full_order_detail')"}, {"cell_type": "code", "execution_count": null, "id": "c01cea93-d182-4d42-829e-241f9e42d27b", "metadata": {"tags": []}, "outputs": [], "source": "spark.sql('show tables')"}, {"cell_type": "code", "execution_count": null, "id": "3f97a40e-293b-4cba-a098-7c9ecd2ee82c", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "03ea2194-fdaa-47dd-89d3-98876e75f88b", "metadata": {"tags": []}, "outputs": [], "source": "full_orders_df.write.mode('overwrite').option('header','true').csv('/data/olist/proc/')"}, {"cell_type": "code", "execution_count": null, "id": "fd2b3424-4a2f-4e84-9e84-44c212bd21ad", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}